# 项目周报

日期：2025-04-13

项目实践题目：文本向量化的高级技术

## 实践内容
       本周读了SLP的 CHAPTER 6的前八节，这段内容从语义的传统表达引入，再延伸出向量式的表达。
       
       在介绍传统表达时从同义词，近义词和反义词等提供了知识基础，为下文铺垫。其中,“life”和“LIFE”那个哲学笑话在展示语言的模糊美时也反映了传统表达方式的不足：歧义。
       
       所有文字其实都是符号，因被赋予意义且被大部分人公知从而成为文字，由于一个词可能会被赋予不同含义，从而出现多义词，多义词在很多时候会产生歧义。
       
       因而延伸出的观点就是一个单词的意思其实更看重其上下文和语境，相似词语出现在相同的语境中的概率更大，例如“狗”和“猫”都会出现在“宠物”，“撕咬”，“叫”的上下文中。
       
       在有了这个观点之后，笔者用三个词语分配权重的方式来反映另一个词语，试发寻找不同词语的相关权重值是否与其相似度有关。这其实就是一种文字向量化的雏形。
       
       再往后的内容就是介绍余弦相似度,TF-IDF,点互信息等向量化基础,如向量余弦多用于表示词的相似度，TF-IDF用于突出文章重点词汇，点互信息用于缓解噪声....等

        同时也完成了第七周支线任务，对于这种远程链接服务器的操作，在做实验的时候已经试过了，实验时是自己的虚拟机连自己的本机，现在是连远程服务器。
    
        步骤大抵相似，在配置环境的时候都是麻烦无比。但是连别人的服务器与自己创建的虚拟机很大一点不同就是权限。我想用sudo命令下载jupyter的时候被拒绝了 转而用pip --user。
        
        同时我直接在终端输jupyter notebook之后也有可能无法在本机打开，最好加上--ip=0.0.0.0等参数。
        
        除此以外的使用其实与本地写代码差不多，因为trae的图形化界面确实极大缩减了指令方面的工作量，不必去频繁的：nano打开代码文件->修改->编译错误-又打开。总而言之的感受就是先苦后甜吧,前期先配置好环境，后面写代码就舒服很多。

        读了gionis的论文，他的提到向量检索的一大难点是维度爆炸，在高纬度时的检索效果非常差。
        
        而他使用的方法是修改距离的表示方法，避免存储过高维数的向量，减少存储成本。同时用LSH方法使降维相似点碰撞概率高，而不相似的点碰撞概率低。

        也就是说思路主要从降维入手，前者降低超高维度时的存储开销，后者保证降维的准确度。（maybe？）
        

        本周主要收获就是这么多，读英文文献主要是关键单词的词汇量问题，一篇文章中的核心词汇掌握后读起来明显顺畅许多，即使有一些生疏的边缘单词突然出现，也能大致明白表达的意思，越发体会到“知意而忘言”
